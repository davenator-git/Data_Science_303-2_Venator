{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Code\"\n",
    "subtitle: JHED\n",
    "author: Hiba Khatib, Emily Leibfritz, David Venator, Jazmyn Lu\n",
    "date: 03/13/2023\n",
    "number-sections: true\n",
    "abstract: _This file contains the code for the project on <>, as part of the STAT303-2 course in Winter 2023_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c4d20",
   "metadata": {},
   "source": [
    "# Many redundant libraries are loaded, some have different names so need to agree on one and update uses throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b586771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                           accuracy_score)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.** An example is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db149d8b",
   "metadata": {},
   "source": [
    "### Data quality check\n",
    "*By Elton John*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc82e7f",
   "metadata": {},
   "source": [
    "The code below visualizes the distribution of all the variables in the dataset, and their association with the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5955618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Distribution of continuous variables...#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8faafdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Distribution of categorical variables...#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e389f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Association of the response with the predictors...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1561829",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "*By Xena Valenzuela*\n",
    "\n",
    "From the data quality check we realized that:\n",
    "\n",
    "1. Some of the columns that should have contained only numeric values, specifically <>, <>, and <> have special characters such as \\*, #, %. We'll remove these characters, and convert the datatype of these columns to numeric.\n",
    "\n",
    "2. Some of the columns have more than 60% missing values, and it is very difficult to impute their values, as the values seem to be missing at random with negligible association with other predictors. We'll remove such columns from the data.\n",
    "\n",
    "3. The column `number_of_bedrooms` has some unreasonably high values such as 15. As our data consist of single-family homes in Evanston, we suspect that any value greater than 5 may be incorrect. We'll replace all values that are greater than 5 with an estimate obtained using the $K$-nearest neighbor approach.\n",
    "\n",
    "4. The columns `house_price` has some unreasonably high values. We'll tag all values greater than 1 billion dollars as \"potentially incorrect observation\", to see if they distort our prediction / inference later on.\n",
    "\n",
    "The code below implements the above cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f73626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...Code with comments...#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91a14e",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "*By Sankaranarayanan Balasubramanian and Chun-Li*\n",
    "\n",
    "The following data preparation steps helped us to prepare our data for implementing various modeling / validation techniques:\n",
    "\n",
    "1. Since we need to predict house price, we derived some new predictors *(from existing predictors)* that intuitively seem to be helpuful to predict house price. \n",
    "\n",
    "2. We have shuffled the dataset to prepare it for K-fold cross validation.\n",
    "\n",
    "3. We have created a standardized version of the dataset, as we will use it to develop Lasso / Ridge regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b2b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######---------------Creating new predictors----------------#########\n",
    "\n",
    "#Creating number of bedrooms per unit floor area\n",
    "\n",
    "#Creating ratio of bathrooms to bedrooms\n",
    "\n",
    "#Creating ratio of carpet area to floor area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e04063",
   "metadata": {},
   "outputs": [],
   "source": [
    "######-----------Shuffling the dataset for K-fold------------#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######-----Standardizing the dataset for Lasso / Ridge-------#########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model\n",
    "\n",
    "**All of the folllowing code produced by Hiba Khatib & Emily Leibfritz**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Put code with comments. The comments should explain the code such that it can be easily understood. You may put text *(in a markdown cell)* before a large chunk of code to explain the overall purpose of the code, if it is not intuitive. **Put the name of the person / persons who contributed to each code chunk / set of code chunks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = train_with_age.drop(columns = ['PassengerId', 'Name', 'Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690503d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model1 = sm.logit(formula = 'Survived~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + age_binned', data = final_train).fit()\n",
    "logit_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = train_with_age.drop(columns = ['PassengerId', 'Name', 'Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded307ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = pd.get_dummies(final_train, columns = ['Sex'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec36999",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.rename(columns={\"Sex_male\": \"Sex\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train['Embarked'] = final_train['Embarked'].apply(lambda x: 1 if x == 'S' else \n",
    "                                                               2 if x == 'C' else \n",
    "                                                               0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39af2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99973c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = final_train.Survived\n",
    "X = final_train.drop('Survived', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073298ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('age_binned', axis = 1)\n",
    "X_test = X_test.drop('age_binned', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6922add",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = LogisticRegression(max_iter=500)\n",
    "sklearn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab98b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = sklearn_model.predict(X_test)\n",
    "print('Accuracy of logistic regression on test set : {:.4f}'.format(sklearn_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_reg(X,Y):\n",
    "    #Fit linear regression model and return RSS and R squared values\n",
    "    model_k = linear_model.LogisticRegression()\n",
    "    model_k.fit(X,Y)\n",
    "    RSS = mean_squared_error(Y,model_k.predict(X)) * len(Y)\n",
    "    R_squared = model_k.score(X,Y)\n",
    "    return RSS, R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "RSS_list, R_squared_list, feature_list = [],[], []\n",
    "numb_features = []\n",
    "\n",
    "#Looping over k = 1 to k = 11 features in X\n",
    "for k in tnrange(1,len(X_train.columns) + 1, desc = 'Loop...'):\n",
    "\n",
    "    #Looping over all possible combinations: from 11 choose k\n",
    "    for combo in itertools.combinations(X_train.columns,k):\n",
    "        tmp_result = fit_logistic_reg(X_train[list(combo)],y_train)   #Store temp result \n",
    "        RSS_list.append(tmp_result[0])                  #Append lists\n",
    "        R_squared_list.append(tmp_result[1])\n",
    "        feature_list.append(combo)\n",
    "        numb_features.append(len(combo))   \n",
    "\n",
    "#Store in DataFrame\n",
    "df = pd.DataFrame({'numb_features': numb_features,'RSS': RSS_list, 'R_squared':R_squared_list,'features':feature_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df[df.groupby('numb_features')['RSS'].transform(min) == df['RSS']]\n",
    "df_max = df[df.groupby('numb_features')['R_squared'].transform(max) == df['R_squared']]\n",
    "display(df_min.head(10))\n",
    "display(df_max.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e12b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_RSS'] = df.groupby('numb_features')['RSS'].transform(min)\n",
    "df['max_R_squared'] = df.groupby('numb_features')['R_squared'].transform(max)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "ax.scatter(df.numb_features,df.RSS, alpha = .2, color = 'darkblue' )\n",
    "ax.set_xlabel('# Features')\n",
    "ax.set_ylabel('RSS')\n",
    "ax.set_title('RSS - Best subset selection')\n",
    "ax.plot(df.numb_features,df.min_RSS,color = 'r', label = 'Best subset')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.scatter(df.numb_features,df.R_squared, alpha = .2, color = 'darkblue' )\n",
    "ax.plot(df.numb_features,df.max_R_squared,color = 'r', label = 'Best subset')\n",
    "ax.set_xlabel('# Features')\n",
    "ax.set_ylabel('R squared')\n",
    "ax.set_title('R_squared - Best subset selection')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a389f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"numb_features\"] == 6)].sort_values(by = ['R_squared'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"numb_features\"] == 7)].sort_values(by = ['R_squared'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2768ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selected variables: (Pclass, Age, SibSp, Parch, Embarked, Sex)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1462a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('Fare', axis = 1)\n",
    "X_test = X_test.drop('Fare', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = sklearn_model.predict(X_test)\n",
    "print('Accuracy of logistic regression on test set : {:.4f}'.format(sklearn_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0881e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train['SibSp'] = pd.to_numeric(final_train['SibSp'])\n",
    "final_train['Parch'] = pd.to_numeric(final_train['Parch'])\n",
    "final_train['Pclass'] = pd.to_numeric(final_train['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacation between SibSp and Parch\n",
    "\n",
    "def jitter(values,j):\n",
    "    return values + np.random.normal(j,0.02,values.shape)\n",
    "sns.scatterplot(x=jitter(final_train.SibSp,0), y = jitter(final_train.Parch,0),data = final_train, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a75a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSP\n",
    "sns.scatterplot(x = jitter(final_train.SibSp,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~SibSp', data = final_train).fit()\n",
    "sns.lineplot(x = 'SibSp', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SibSP squared\n",
    "sns.scatterplot(x = jitter(final_train.SibSp,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~SibSp+I(SibSp**2)', data = final_train).fit()\n",
    "sns.lineplot(x = 'SibSp', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc59a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch\n",
    "sns.scatterplot(x = jitter(final_train.Parch,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~Parch', data = final_train).fit()\n",
    "sns.lineplot(x = 'Parch', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch squared\n",
    "sns.scatterplot(x = jitter(final_train.Parch,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~Parch+I(Parch**2)', data = final_train).fit()\n",
    "sns.lineplot(x = 'Parch', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age not binned\n",
    "sns.scatterplot(x = jitter(final_train.Age,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~Age', data = final_train).fit()\n",
    "sns.lineplot(x = 'Age', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age binned\n",
    "sns.scatterplot(x = jitter(final_train.Age,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~age_binned', data = final_train).fit()\n",
    "sns.lineplot(x = 'Age', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age squared\n",
    "sns.scatterplot(x = jitter(final_train.Age,0), y = jitter(final_train.Survived,0), color = 'orange')\n",
    "model = smf.logit(formula = 'Survived~Age+I(Age**2)', data = final_train).fit()\n",
    "sns.lineplot(x = 'Age', y= model.predict(final_train), data = final_train, color = 'blue') \n",
    "model.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a179a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'age_binned',hue = 'Survived', data = final_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4073d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.copy()\n",
    "X_train1['Age_binned'] = final_train['age_binned']\n",
    "X_train1['agePclass']= final_train.Age * final_train.Pclass\n",
    "X_train1['ParchSibSp']= final_train.SibSp * final_train.Parch\n",
    "X_train1['EmbarkedPclass']= final_train.Embarked * final_train.Pclass\n",
    "X_train1 = X_train1.drop(['Age_binned'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9621e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test.copy()\n",
    "X_test1['Parch'] = pd.to_numeric(X_test1.Parch)\n",
    "X_test1['SibSp'] = pd.to_numeric(X_test1.SibSp)\n",
    "X_test1['Pclass'] = pd.to_numeric(X_test1.Pclass)\n",
    "X_test1['agePclass']= X_test1.Age * X_test1.Pclass\n",
    "X_test1['ParchSibSp']= X_test1.SibSp * X_test1.Parch\n",
    "X_test1['EmbarkedPclass']= X_test1.Embarked * X_test1.Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444e611",
   "metadata": {},
   "source": [
    "### Code fitting the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cae72f",
   "metadata": {},
   "source": [
    "Put the code(s) that fit the final model(s) in separate cell(s), i.e., the code with the `.ols()` or `.logit()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model_1 = LogisticRegression()\n",
    "sklearn_model_1.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = sklearn_model_1.predict(X_test1)\n",
    "print('Accuracy of logistic regression on test set : {:.4f}'.format(sklearn_model_1.score(X_test1, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d531c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986bdec",
   "metadata": {},
   "source": [
    "### Performance Measurement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef027ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test) \n",
    "print (\"Confusion Matrix : \\n\", cm) \n",
    "  \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                               display_labels=sklearn_model_1.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa62692",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(sklearn_model_1, X_test1, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = sklearn_model_1.predict(X_train1)\n",
    "y = y_train\n",
    "# ypred = logit_model_diabetes.predict(train)\n",
    "p, r, thresholds = precision_recall_curve(y, ypred)\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.legend()\n",
    "plot_precision_recall_vs_threshold(p, r, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "# You may or may not have code to put in this section. Delete this section if it is irrelevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
